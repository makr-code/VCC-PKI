
Strategiedokument: Zero-Trust-Architektur für ein KI-gestütztes RAG-System im Verwaltungsumfeld


Executive Summary


Strategische Rationale

Die digitale Transformation im öffentlichen Sektor erfordert den Einsatz fortschrittlicher Technologien wie Künstlicher Intelligenz (KI), um die Effizienz zu steigern, Dienstleistungen für Bürger zu verbessern und komplexe Datenbestände nutzbar zu machen. Gleichzeitig führt die zunehmende Vernetzung und die Raffinesse von Cyberangriffen dazu, dass traditionelle, perimeterbasierte Sicherheitsmodelle obsolet werden. Dieses Strategiedokument legt den Grundstein für eine zukunftsfähige, sichere und souveräne IT-Infrastruktur, indem es eine umfassende Zero-Trust-Architektur (ZTA) für ein KI-gestütztes Retrieval-Augmented Generation (RAG)-System im Verwaltungsumfeld definiert. Die Abkehr von implizitem Vertrauen hin zu einem Modell der expliziten, kontinuierlichen Verifizierung ist keine optionale Modernisierung, sondern eine strategische Notwendigkeit, um sensible Regierungs- und Bürgerdaten zu schützen und gleichzeitig die Potenziale der KI verantwortungsvoll zu erschließen. Diese Architektur ist die Voraussetzung für die Wahrung der digitalen Souveränität bei der Nutzung von KI zur Verbesserung öffentlicher Dienstleistungen.

Kernprinzipien

Die vorgeschlagene Architektur basiert auf den fundamentalen Grundsätzen des Zero-Trust-Modells, wie sie im NIST Special Publication 800-207 definiert sind. Diese Prinzipien bilden das unumstößliche Fundament aller nachfolgenden technischen und organisatorischen Maßnahmen 1:
1.	Niemals vertrauen, immer verifizieren (Never Trust, Always Verify): Jede Zugriffsanfrage, unabhängig von ihrem Ursprung (intern oder extern), wird als potenziell feindlich betrachtet und muss streng authentifiziert und autorisiert werden, bevor der Zugriff gewährt wird.
2.	Von einer Kompromittierung ausgehen (Assume Breach): Die Architektur ist so konzipiert, dass sie die Auswirkungen eines erfolgreichen Angriffs minimiert. Anstatt sich ausschließlich auf die Prävention zu konzentrieren, liegt der Fokus auf der schnellen Erkennung, Eindämmung und Reaktion, um die laterale Ausbreitung von Bedrohungen im Netzwerk zu verhindern.
3.	Zugriff mit den geringsten Rechten (Least-Privileged Access): Benutzern, Geräten und Diensten werden nur die minimal erforderlichen Berechtigungen für die Ausführung ihrer spezifischen Aufgaben gewährt. Dieser Zugriff wird dynamisch und pro Sitzung evaluiert und durchgesetzt.

Architektonische Säulen

Die Umsetzung dieser Prinzipien stützt sich auf vier technologische und konzeptionelle Säulen, die ein robustes und resilientes Sicherheitsökosystem bilden:
●	Hybrides Identitäts- und Zugriffsmanagement (IAM): Eine Kombination aus dem etablierten On-Premise Active Directory (AD) und der flexiblen Open-Source-Lösung Keycloak als Identity Broker. Diese Strategie ermöglicht die Nutzung moderner Authentifizierungsprotokolle (OIDC/OAuth 2.0) für das RAG-System, während die bestehende AD-Infrastruktur für die zentrale Benutzerverwaltung weitergenutzt wird.
●	Polyglotte Persistenz und prozessuale Integrität: Die Anerkennung, dass unterschiedliche Daten unterschiedliche Speichertechnologien erfordern (Polyglot Persistence), wird durch eine einheitliche Datenstrategie (UDS3) umgesetzt. Die daraus resultierende Notwendigkeit verteilter Transaktionen wird durch das Saga-Pattern adressiert, das die Prozessintegrität über Systemgrenzen hinweg sicherstellt. Die bewusste Wahl des Orchestrierungsmodells für Sagas garantiert eine lückenlose Auditierbarkeit, die für die Rechtssicherheit im Verwaltungshandeln unerlässlich ist.69
●	Netzwerk-Mikrosegmentierung: Die strikte Isolation aller Systemkomponenten in granularen Netzwerksegmenten. Die Standardrichtlinie verweigert jegliche Kommunikation; explizite, streng definierte Regeln erlauben den Datenverkehr nur zwischen autorisierten Diensten auf den notwendigen Ports und Protokollen.
●	Anwendungsorchestrierte Datensicherheit: Die Durchsetzung von Datensicherheitsrichtlinien, insbesondere dynamischer Row-Level Security (RLS), erfolgt auf der Anwendungsebene. Dies gewährleistet eine konsistente und datenbankunabhängige Kontrolle darüber, welche Daten ein Benutzer sehen darf, und verhindert den unbefugten Zugriff auf sensible Informationen durch das KI-Modell.
●	Kontinuierliche Überwachung und dynamische Richtlinien: Alle Zugriffsversuche und Systemaktivitäten werden zentral protokolliert und in Echtzeit analysiert. Diese Telemetriedaten fließen in eine dynamische Policy Engine ein, die Zugriffsentscheidungen kontextbezogen anpasst, basierend auf Identität, Gerätestatus, Standort und Verhaltensanomalien.

Wesentliche Vorteile

Die Implementierung dieser Zero-Trust-Architektur führt zu quantifizierbaren und strategischen Vorteilen, die über die reine Risikominderung hinausgehen:
●	Reduzierte Angriffsfläche: Durch die Mikrosegmentierung und das Verstecken von Anwendungen hinter einem Policy Enforcement Point werden Dienste für unautorisierte Akteure unsichtbar, was die Angriffsfläche drastisch verkleinert.3
●	Verhinderung lateraler Bewegungen: Die granulare Segmentierung und die strikte Zugriffskontrolle zwischen den Diensten verhindern, dass ein kompromittiertes System als Sprungbrett für Angriffe auf andere Teile des Netzwerks genutzt werden kann.1
●	Verbesserter Datenschutz und Compliance: Die Architektur bietet detaillierte Einblicke in Zugriffsanfragen und setzt das Prinzip der geringsten Rechte konsequent um. Dies verbessert den Schutz personenbezogener und sensibler Daten und unterstützt die Einhaltung gesetzlicher Vorschriften wie der DSGVO.1
●	Sichere Grundlage für KI-Innovation: Durch die Schaffung einer inhärent sicheren Umgebung ermöglicht die ZTA der Verwaltung, zukünftige KI-gestützte Initiativen vertrauensvoll und ohne Kompromisse bei der Sicherheit zu entwickeln und zu betreiben.
________________________________________
Abschnitt 1: Strategische Imperative für eine modernisierte und sichere Infrastruktur der öffentlichen Verwaltung


1.1 Die Obsoleszenz des Perimetermodells

Das traditionelle Sicherheitsmodell, oft als "Burg-und-Graben"-Ansatz ("castle-and-moat") beschrieben, basiert auf der Annahme einer klaren Trennung zwischen einem vertrauenswürdigen internen Netzwerk und einer nicht vertrauenswürdigen externen Welt.4 In diesem Modell wird erheblicher Aufwand betrieben, um eine starke äußere Verteidigungslinie (die "Burgmauer" oder Firewall) zu errichten. Sobald ein Benutzer oder ein Gerät diese Hürde überwunden hat und sich "innerhalb der Mauern" befindet, wird ihm ein hohes Maß an implizitem Vertrauen entgegengebracht.
Diese Annahme ist in der heutigen IT-Landschaft nicht mehr haltbar. Die Tage, an denen alle elektronischen Ressourcen in einem einzigen Gebäude untergebracht und durch eine einfache Firewall geschützt werden konnten, sind vorbei.5 Faktoren wie die Zunahme von Fernarbeit, die Nutzung mobiler Geräte, die Integration von Cloud-Diensten und die komplexe Vernetzung mit externen Partnern haben den traditionellen Netzwerkperimeter aufgelöst. Die Angriffsfläche ist nicht mehr klar definiert, sondern diffus und ständig im Wandel.
Darüber hinaus konzentriert sich das Perimetermodell primär auf externe Bedrohungen und vernachlässigt die signifikanten Risiken, die von innen ausgehen. Insider-Bedrohungen, ob böswillig oder fahrlässig, sowie Angriffe auf die Lieferkette, bei denen vertrauenswürdige Drittanbieter kompromittiert werden, können die äußere Verteidigungslinie umgehen.1 Sobald ein Angreifer im internen Netzwerk Fuß gefasst hat, ermöglicht ihm das implizite Vertrauen oft eine ungehinderte laterale Bewegung, um wertvolle Daten und Systeme zu kompromittieren.6

1.2 Zero Trust als strategischer Wegbereiter

Zero Trust ist keine einzelne Technologie oder ein Produkt, sondern eine strategische Neuausrichtung der Cybersicherheit. Es ist eine Sammlung von Leitprinzipien für Arbeitsabläufe, Systemdesign und Betrieb, die die Sicherheitslage einer Organisation grundlegend verbessern.1 Der Kern dieser Strategie ist die Abkehr von implizitem Vertrauen basierend auf dem Netzwerkstandort und die Hinwendung zu einer expliziten, dynamischen und kontextbezogenen Verifizierung jeder einzelnen Zugriffsanfrage.7
Diese Neuausrichtung ist mehr als nur ein technisches Upgrade; sie erfordert eine fundamentale Veränderung in der Denkweise und den Prozessen einer Organisation. Die traditionelle, standortzentrierte Sichtweise der Sicherheit – "innen" versus "außen" – wird durch ein identitäts- und datenzentriertes Modell ersetzt. Dies hat weitreichende Konsequenzen. Prozesse, die sich bisher auf den Netzwerkstandort als Vertrauensanker verließen, wie beispielsweise eine interne Anwendung, die den Zugriff ohne erneute Authentifizierung erlaubt, sind in einem Zero-Trust-Modell nicht mehr gültig. Stattdessen muss jeder Geschäftsprozess neu bewertet werden, um Arbeitsabläufe genau zu verstehen und explizite Zugriffsrichtlinien zu definieren.4 Diese Notwendigkeit erzwingt eine tiefere Zusammenarbeit zwischen den Sicherheitsteams und den Fachabteilungen. Sicherheit wird von einer isolierten Funktion zu einem integralen Bestandteil des gesamten Lebenszyklus der Dienstleistungserbringung. Die erfolgreiche Implementierung von Zero Trust ist somit nicht nur eine technologische, sondern auch eine organisatorische Herausforderung, die eine kulturelle Transformation voraussetzt.

1.3 Das Versprechen und die Gefahr von KI in der öffentlichen Verwaltung

Retrieval-Augmented Generation (RAG)-Systeme stellen einen Paradigmenwechsel für das Wissensmanagement in der öffentlichen Verwaltung dar. Sie ermöglichen es, riesige, unstrukturierte Datenbestände – von Gesetzes- und Verordnungstexten über interne Richtlinien bis hin zu historischen Akten – intelligent zu erschließen. Mitarbeiter können komplexe Anfragen in natürlicher Sprache stellen und erhalten präzise, kontextbezogene und auf Fakten basierende Antworten. Dies hat das Potenzial, die Effizienz von Verwaltungsprozessen drastisch zu erhöhen, die Einarbeitungszeit für neue Mitarbeiter zu verkürzen und die Qualität der bürgernahen Dienstleistungen signifikant zu verbessern.
Gleichzeitig führen diese Systeme jedoch neue und komplexe Risiken ein, für deren Abwehr traditionelle Sicherheitsmodelle unzureichend sind. Die Angriffsfläche eines RAG-Systems ist vielschichtig und umfasst neuartige Vektoren wie:
●	Datenvergiftung (Data Poisoning): Das gezielte Einschleusen von manipulierten oder falschen Informationen in die Wissensdatenbank, um die KI zu irreführenden oder schädlichen Antworten zu verleiten.
●	Modell-Diebstahl: Der unbefugte Zugriff und die Exfiltration der trainierten KI-Modelle, die ein wertvolles geistiges Eigentum darstellen.
●	Gezielte Prompt-Injektionen: Speziell formulierte Anfragen, die darauf abzielen, die Sicherheitsmechanismen der KI zu umgehen, um sensible Informationen preiszugeben oder unautorisierte Aktionen auszuführen.
Ein Zero-Trust-Ansatz ist unerlässlich, um diesen spezifischen Bedrohungen zu begegnen, indem er den Zugriff auf jede Komponente des RAG-Systems – von der Wissensdatenbank bis zum Sprachmodell selbst – streng kontrolliert und überwacht.

1.4 Abgleich von Sicherheit mit digitaler Souveränität

Für öffentliche Verwaltungen ist die digitale Souveränität von überragender Bedeutung. Sie bezeichnet die Fähigkeit des Staates, seine IT-Systeme und die darauf verarbeiteten Daten selbstbestimmt und unabhängig zu kontrollieren. Die Entscheidung für eine On-Premise- oder eine souveräne Hybrid-Cloud-Bereitstellung des RAG-Systems ist ein zentraler Baustein zur Wahrung dieser Souveränität.
Eine robuste Zero-Trust-Architektur, die speziell für ein solches On-Premise-Szenario konzipiert ist, bildet das Fundament dieser Strategie. Sie stellt sicher, dass sensible Regierungs- und Bürgerdaten sowie die KI-Modelle, die diese Daten verarbeiten, unter der vollständigen Kontrolle und Jurisdiktion der Verwaltung bleiben. Indem jeder Zugriff auf Daten und Dienste explizit verifiziert wird, unabhängig davon, wo er stattfindet, schafft Zero Trust ein Sicherheitsmodell, das die Souveränität nicht nur ermöglicht, sondern aktiv durchsetzt. Es stellt den notwendigen technischen Unterbau dar, um die Kontrolle über die kritischsten digitalen Vermögenswerte des Staates zu gewährleisten.
________________________________________
Abschnitt 2: Das Zero-Trust-Architektur-Framework: Prinzipien und Komponenten


2.1 Kernprinzipien von Zero Trust

Die vorgeschlagene Architektur basiert auf drei unumstößlichen Kernprinzipien, die zusammen ein dynamisches und widerstandsfähiges Sicherheitsmodell bilden.

2.1.1 Niemals vertrauen, immer verifizieren

Dies ist das grundlegendste Prinzip von Zero Trust. Es eliminiert das Konzept des impliziten Vertrauens vollständig. Kein Benutzer, kein Gerät und keine Anwendung wird standardmäßig als vertrauenswürdig eingestuft, selbst wenn sie sich bereits im Unternehmensnetzwerk befinden.7 Jede einzelne Zugriffsanfrage muss authentifiziert und autorisiert werden. Dies gilt nicht nur für den initialen Zugriff, sondern für jede Interaktion während einer Sitzung. Darüber hinaus wird die gesamte Kommunikation, sowohl innerhalb des Netzwerks als auch nach außen, als potenziell unsicher behandelt und muss mit den stärksten verfügbaren Methoden geschützt und verschlüsselt werden.1 Dieser kontinuierliche Verifizierungsprozess stellt sicher, dass eine kompromittierte Entität sich nicht frei im Netzwerk bewegen kann.

2.1.2 Von einer Kompromittierung ausgehen

Zero Trust operiert unter der Annahme, dass eine Sicherheitsverletzung nicht nur eine Möglichkeit, sondern eine unvermeidliche Gegebenheit ist.7 Diese "Assume Breach"-Mentalität zwingt die Sicherheitsteams, Kontrollen zu entwerfen, die Bedrohungen eindämmen können, die bereits die erste Verteidigungslinie überwunden haben. Anstatt sich ausschließlich auf die Prävention am Perimeter zu konzentrieren, verlagert sich der Fokus auf die interne Überwachung, die Erkennung von Bedrohungen und eine schnelle Reaktion, um die laterale Bewegung zu stoppen und die Auswirkungen einer Kompromittierung zu minimieren. Der sogenannte "Blast Radius" – der potenzielle Schaden, den ein einzelner kompromittierter Account oder ein System anrichten kann – wird durch granulare Segmentierung und strikte Kontrollen drastisch reduziert.
Die "Assume Breach"-Mentalität verändert die Rolle der Überwachung von Grund auf. Sie ist nicht länger ein passives, forensisches Werkzeug, das nach einem Vorfall zur Analyse herangezogen wird, sondern ein aktiver Echtzeit-Verteidigungsmechanismus. Das primäre Ziel eines Angreifers, der sich bereits im Netzwerk befindet, ist die laterale Bewegung, um Zugang zu hochwertigen Zielen zu erlangen.3 Daher müssen die Sicherheitskontrollen darauf ausgerichtet sein, genau diese Bewegung zu verhindern, was hauptsächlich durch Mikrosegmentierung erreicht wird.7 Segmentierung allein ist jedoch nicht ausreichend. Das System muss in der Lage sein,
Versuche einer unbefugten lateralen Bewegung zu erkennen. Dies erfordert eine kontinuierliche Echtzeit-Überwachung des Verhaltens von Benutzern und Diensten, um Anomalien zu identifizieren.1 Eine Zugriffsanfrage von einem legitimen Dienst an einen anderen Dienst, mit dem er noch nie zuvor kommuniziert hat, stellt beispielsweise einen Alarm höchster Priorität dar. Dies hebt die Überwachung von einem reinen Compliance-Thema zu einer Kernkomponente der aktiven Verteidigungsstrategie, die direkt in die dynamische Entscheidungsfindung der Policy Engine einfließt.

2.1.3 Zugriff mit den geringsten Rechten

Das Prinzip des geringsten Privilegs (Least Privilege) stellt sicher, dass einem Benutzer, einem Gerät oder einem Dienst nur das absolute Minimum an Zugriffsrechten gewährt wird, das zur Erfüllung seiner spezifischen Funktion erforderlich ist.7 Dieser Zugriff ist nicht statisch, sondern wird dynamisch und "just-in-time" gewährt. Jede Verbindung zu kritischen Ressourcen wird nur auf einer Pro-Sitzungs-Basis hergestellt.1 Dies reduziert den potenziellen Schaden, den ein kompromittierter Account anrichten kann, erheblich und schränkt die Möglichkeiten eines Angreifers ein, seine Privilegien zu erweitern.

2.2 Das NIST SP 800-207 Modell

Um eine strukturierte und standardisierte Implementierung von Zero Trust zu gewährleisten, wird das konzeptionelle Modell der NIST Special Publication 800-207 als Referenzrahmen für diese Architektur formell übernommen.1 Dieses Modell definiert die logischen Komponenten eines ZTA-Ökosystems, die zusammenarbeiten, um sichere Zugriffsentscheidungen zu treffen und durchzusetzen.
●	Policy Engine (PE) / Policy Decision Point (PDP): Dies ist das "Gehirn" der Zero-Trust-Architektur. Es handelt sich um eine logische Komponente, die Zugriffsanfragen von einem Subjekt (z.B. Benutzer, Dienst) auf eine Ressource bewertet. Die PE trifft die endgültige Entscheidung, den Zugriff zu gewähren oder zu verweigern, basierend auf den Unternehmensrichtlinien und einer Vielzahl von kontextbezogenen Signalen. Zu diesen Signalen gehören die Identität des Subjekts, der Sicherheitsstatus des Geräts, der Standort, die Tageszeit und Verhaltensanalysen.
●	Policy Administrator (PA) / Policy Administration Point (PAP): Der Policy Administrator ist die Komponente, die die Entscheidung der Policy Engine umsetzt. Er ist dafür verantwortlich, den Kommunikationspfad zwischen dem Subjekt und der Ressource aufzubauen oder zu beenden. Der PA kommuniziert mit dem Policy Enforcement Point, um die Zugriffskontrolle zu aktivieren oder zu deaktivieren.
●	Policy Enforcement Point (PEP): Der Policy Enforcement Point ist das System, das den Zugriff auf eine Ressource letztendlich gewährt, verweigert oder widerruft. Er befindet sich logisch zwischen dem Subjekt und der Ressource und fungiert als Gatekeeper. Der PEP ist dafür verantwortlich, die Kommunikation zu überwachen und zu beenden, falls die Policy Engine die Autorisierung während einer Sitzung widerruft.

2.3 Logische vs. physische Implementierung

Es ist von entscheidender Bedeutung zu verstehen, dass ZTA keine einzelne, monolithische Architektur ist, sondern eine Reihe von Leitprinzipien.1 Das NIST-Framework beschreibt eine logische Anordnung von Komponenten, die auf vielfältige Weise physisch oder technologisch umgesetzt werden kann. Das NIST schlägt verschiedene Ansätze vor, um eine ZTA zu realisieren 1:
●	Identitätszentrierte Kontrollen: Der Fokus liegt auf der strengen Überprüfung der Identität von Benutzern und Geräten und der Durchsetzung von Richtlinien basierend auf diesen Identitäten.
●	Netzwerk-Mikrosegmentierung: Das Netzwerk wird in kleine, isolierte Segmente unterteilt, die jeweils durch eigene Richtlinien und Zugangsregeln geschützt sind. Der Datenverkehr zwischen den Segmenten wird streng kontrolliert.
●	Software-Defined Perimeters (SDP): Ein Ansatz, bei dem der Zugriff auf Anwendungen und Ressourcen auf der Grundlage einer authentifizierten Identität gewährt wird, wodurch die zugrunde liegende Netzwerkinfrastruktur für nicht autorisierte Benutzer unsichtbar wird.
Die in diesem Dokument vorgestellte Strategie verfolgt einen hybriden Ansatz, der die Stärken aller drei Implementierungsmodelle kombiniert. Identitätszentrierte Kontrollen bilden das Fundament, die Netzwerk-Mikrosegmentierung sorgt für die Eindämmung von Bedrohungen, und SDP-Konzepte werden genutzt, um den Zugriff auf das RAG-System zu steuern.
________________________________________
Abschnitt 3: Anatomie des KI-gestützten RAG-Systems und seine inhärente Angriffsfläche


3.1 Dekonstruktion des RAG-Workflows

Ein Retrieval-Augmented Generation (RAG)-System optimiert die Ausgabe eines großen Sprachmodells (Large Language Model, LLM), indem es vor der Generierung einer Antwort auf eine autoritative, externe Wissensdatenbank zugreift.8 Dieser Prozess kombiniert die Stärken traditioneller Informationsabrufsysteme mit den generativen Fähigkeiten von LLMs 9 und lässt sich in vier Hauptschritte unterteilen:
●	1. Benutzeranfrage & Vorverarbeitung (User Query & Pre-processing): Der Prozess beginnt mit einer Anfrage des Benutzers in natürlicher Sprache, die vom API-Gateway des Systems empfangen wird. Diese Anfrage durchläuft eine Vorverarbeitungsphase, in der sie für den Abruf optimiert wird. Dies kann Techniken wie die Korrektur von Rechtschreibfehlern, die Entfernung von Stoppwörtern (Tokenization, Stemming) und die Erweiterung der Anfrage umfassen, um die Relevanz der Suchergebnisse zu maximieren.9
●	2. Abruf (Retrieval): Die vorverarbeitete Anfrage wird in eine numerische Vektorrepräsentation (Embedding) umgewandelt.8 Das System führt dann eine Relevanzsuche in seiner Wissensdatenbank durch. Moderne RAG-Systeme nutzen typischerweise eine hybride Suche, die semantische Ähnlichkeit (über Vektordatenbanken) mit traditioneller Stichwortsuche kombiniert. Ein Re-Ranker bewertet die Suchergebnisse, um sicherzustellen, dass die relevantesten Dokumente an die Spitze gestellt werden.9
●	3. Erweiterung (Augmentation): Die abgerufenen, hochrelevanten Dokumente – der "Kontext" – werden mit der ursprünglichen Benutzeranfrage zu einem erweiterten Prompt zusammengefügt. Diese Technik wird oft als "Prompt Stuffing" bezeichnet.10 Dieser Schritt ist entscheidend, da er dem LLM die spezifischen Fakten und Informationen an die Hand gibt, auf denen die Antwort basieren soll.
●	4. Generierung (Generation): Der erweiterte Prompt wird an das On-Premise LLM gesendet. Das LLM nutzt diesen angereicherten Kontext, um eine präzise, informative und sachlich fundierte Antwort zu generieren.9 Dieser Prozess des "Grounding" auf bereitgestellten Fakten ist der Schlüssel zur Minderung von KI-Halluzinationen, bei denen das Modell ungenaue oder erfundene Informationen ausgibt.8 Das LLM ist darauf programmiert, die im Prompt bereitgestellten neuen Informationen zu priorisieren.10

3.2 Wesentliche architektonische Komponenten

Die Realisierung dieses Workflows erfordert ein Zusammenspiel mehrerer spezialisierter Komponenten, die jeweils eigene Sicherheitsanforderungen haben:
●	API-Gateway: Der zentrale und einzige Eingangspunkt für alle Benutzeranfragen. Es ist verantwortlich für die initiale Authentifizierung, Autorisierung, Ratenbegrenzung und das Routing der Anfragen an den Orchestrierungsdienst.
●	Orchestrierungsdienst: Das Herzstück des Systems. Dieser Dienst implementiert die Geschäftslogik des RAG-Workflows, steuert die Interaktion zwischen den verschiedenen Komponenten, führt die Vorverarbeitung der Anfragen durch, konstruiert den erweiterten Prompt und setzt die Datensicherheitsrichtlinien durch.
●	On-Premise LLM-Dienst: Ein isolierter Dienst, der das große Sprachmodell bereitstellt. Für den Einsatz im Verwaltungsumfeld wird eine On-Premise-Lösung wie Ollama empfohlen, um die volle Kontrolle über das Modell und die Daten zu behalten.11 Dieser Dienst ist rechenintensiv und stellt ein hochwertiges Ziel für Angreifer dar.
●	Polyglotte Persistenz-Wissensdatenbank: Anstatt alle Daten in einer einzigen Datenbanktechnologie zu speichern, nutzt die Architektur einen polyglotten Persistenzansatz. Dieser Ansatz verwendet für jeden Datentyp die jeweils am besten geeignete Speichertechnologie, um die Leistung und Flexibilität zu optimieren.13 Die Wissensdatenbank besteht aus:
○	Vektordatenbank (z.B. ChromaDB): Speichert die numerischen Vektor-Embeddings von Dokumenten. ChromaDB, das intern auf SQLite basiert, ermöglicht eine extrem schnelle und effiziente Suche nach semantischer Ähnlichkeit, was für den Retrieval-Schritt unerlässlich ist.9
○	Graphdatenbank (z.B. Neo4j): Modelliert komplexe Beziehungen, Hierarchien und Zusammenhänge zwischen den Entitäten in den Daten. Dies ermöglicht anspruchsvolle Abfragen, die über eine einfache Textähnlichkeit hinausgehen, z.B. zur Analyse von Organisationsstrukturen oder Abhängigkeiten in Regelwerken.17
○	Relationale Datenbank (z.B. PostgreSQL): Speichert strukturierte Metadaten zu den Dokumenten (z.B. Autor, Erstellungsdatum, Klassifizierungsstufe) sowie die zentralen Informationen zur Benutzer- und Zugriffskontrolle, die für die Durchsetzung der Row-Level Security erforderlich sind.

3.3 Analyse der einzigartigen Angriffsfläche

Die komplexe, mehrstufige Architektur des RAG-Systems schafft eine einzigartige Angriffsfläche, die über traditionelle Webanwendungs-Schwachstellen hinausgeht.
●	Datenvergiftung (Data Poisoning): Ein Angreifer könnte versuchen, die Wissensdatenbank mit manipulierten Daten zu kompromittieren. Dies könnte durch das Einschleusen von Dokumenten mit falschen Informationen oder durch die subtile Veränderung bestehender Datensätze geschehen. Eine erfolgreiche Vergiftung würde die Integrität aller vom RAG-System generierten Antworten untergraben und könnte zu weitreichender Desinformation führen.
●	Modell-Diebstahl & Datenexfiltration: Die LLM-Modellgewichte und die kuratierte Wissensdatenbank stellen ein erhebliches geistiges Eigentum und einen wertvollen Datenschatz dar. Ein Angreifer, der direkten Zugriff auf den LLM-Dienst oder die Vektordatenbank erlangt, könnte diese Assets exfiltrieren.18
●	Gezielte Prompt-Injektion: Dies ist eine KI-spezifische Angriffsform. Angreifer können speziell gestaltete Prompts erstellen, um die "Grounding"-Mechanismen des RAG-Prozesses zu umgehen. Ziel ist es, das LLM dazu zu bringen, seine internen Anweisungen zu ignorieren, sensible Informationen aus dem Kontext preiszugeben, die nicht Teil der beabsichtigten Antwort sein sollten, oder schädliche Aktionen auszuführen.11
●	Denial of Service (DoS): Die Vektorsuche und die LLM-Inferenz sind extrem rechenintensive Operationen. Angreifer könnten das System mit einer Flut von komplexen oder ressourcenintensiven Anfragen überlasten, um einen Denial-of-Service-Zustand herbeizuführen und die Verfügbarkeit des Dienstes zu beeinträchtigen.18
●	Kompromittierung von Komponenten: Jede einzelne Komponente der Architektur stellt ein potenzielles Einfallstor dar. Eine Schwachstelle in der Vektordatenbank, eine Fehlkonfiguration des Ollama-Servers (z.B. ein offener, unauthentifizierter API-Endpunkt) oder eine Sicherheitslücke im Orchestrierungsdienst könnte von einem Angreifer ausgenutzt werden, um einen ersten Fuß in das System zu bekommen und von dort aus laterale Bewegungen zu starten.11
Der RAG-Prozess trennt den Abruf von der Generierung, wobei die Generierung durch den aus dem Abruf bereitgestellten Kontext "gegroundet" wird.8 Das LLM ist darauf programmiert, diese neuen Informationen zu priorisieren.10 Dies bedeutet, dass die Integrität des gesamten Systems von der Integrität des abgerufenen Kontexts abhängt. Wenn ein Angreifer den Abrufschritt manipulieren kann – sei es durch die Vergiftung der Vektordatenbank oder die Kompromittierung des Orchestrierungsdienstes –, kann er die "Fakten" kontrollieren, die das LLM sieht. Dies könnte genutzt werden, um Antworten subtil zu verzerren, bösartige Links in die Antworten einzuschleusen oder das LLM dazu zu bringen, Teile sensibler Daten aus anderen Dokumenten preiszugeben, die fälschlicherweise abgerufen wurden. Folglich ist die Sicherung der Abrufpipeline – des Orchestrierungsdienstes und der Wissensdatenbank – wohl kritischer als die Sicherung des LLM selbst. Die Zero-Trust-Kontrollen müssen daher um diese Komponenten herum am strengsten sein.

3.4 Die Unified Database Strategy (UDS3) in der Praxis

Die praktische Umsetzung der Polyglot-Persistence-Philosophie wird durch eine einheitliche Datenstrategie (Unified Database Strategy, UDS3) realisiert, die durch eine dedizierte Adapterschicht implementiert wird.69 Diese Schicht, oft als "UDS3 Backend Worker" bezeichnet, ist die Verkörperung des Prinzips, für jede Aufgabe das beste Werkzeug zu verwenden. Ihre Aufgabe ist es nicht, Daten einfach nur abzulegen, sondern eine intelligente Verteilung basierend auf der Natur der Information vorzunehmen.69
Der Datenverarbeitungsworkflow innerhalb der ereignisgesteuerten Covina-Architektur wird von einem "Core Orchestrator" gesteuert, der dynamisch eine Kette von Verarbeitungsschritten zusammenstellt. Der UDS3-Worker ist ein zentraler Akteur in dieser Kette 69:
1.	Extraktion von Beziehungen: Ein spezialisierter Worker analysiert unstrukturierte Texte (z. B. einen Genehmigungsbescheid) und extrahiert mithilfe von KI-Modellen Entitäten und deren Beziehungen.69
2.	Intelligente Verteilung durch UDS3: Das extrahierte Ergebnis, z. B. das Tripel (Gutachten G-456, IST_GRUNDLAGE_FÜR, Auflage 3.1), wird an den UDS3 Backend Worker übergeben. Dieser erkennt, dass es sich um eine explizite Beziehung handelt, und speichert diese Information als Knoten und Kante in der Graph-Datenbank.69
3.	Parallele Verarbeitung: Gleichzeitig werden Textabschnitte des Dokuments von einem LLM-Worker in numerische Vektoren umgewandelt. Der UDS3-Worker leitet diese Vektoren zur Speicherung an die Vektor-Datenbank weiter. Strukturierte Metadaten wie Aktenzeichen oder Datum werden in einer relationalen Datenbank abgelegt.69
Dieser hybride Ansatz, der durch die UDS3-Schicht ermöglicht wird, ist der Schlüssel zur Leistungsfähigkeit des Gesamtsystems. Er verbindet die Effizienz der Vektorsuche mit der Präzision und Erklärbarkeit der Graphenanalyse und zeigt, dass Polyglot Persistence eine pragmatische und notwendige Grundlage für intelligente Verwaltungssysteme ist.69
________________________________________
Abschnitt 4: Identität als Fundament: Eine hybride IAM-Strategie

In einer Zero-Trust-Architektur ist die Identität der Dreh- und Angelpunkt aller Sicherheitsentscheidungen. Die Fähigkeit, die Identität jedes Benutzers, Geräts und Dienstes eindeutig und sicher zu überprüfen, ist die Grundvoraussetzung für die Durchsetzung dynamischer und granularer Zugriffsrichtlinien. Angesichts der bestehenden Infrastruktur im Verwaltungsumfeld und der Anforderungen moderner, API-gesteuerter Anwendungen wird eine dreistufige, hybride IAM-Strategie vorgeschlagen.

4.1 Benutzer- und Geräteidentität: Ein hybrides AD- und Keycloak-Modell


4.1.1 Rationale für den hybriden Ansatz

Die öffentliche Verwaltung hat über Jahrzehnte in On-Premise Active Directory (AD) investiert. AD ist tief in der bestehenden IT-Landschaft verankert und dient als zentrale Autorität für die Verwaltung von Benutzeridentitäten und domänengebundenen Computern.21 AD verlässt sich jedoch auf traditionelle Authentifizierungsprotokolle wie Kerberos und NTLM, die für die Sicherung von Web-APIs und modernen Microservice-Architekturen schlecht geeignet sind.22 Eine vollständige Migration zu einer reinen Cloud-Lösung wie Microsoft Entra ID ist oft aufgrund von Bedenken hinsichtlich der Datenhoheit und der hohen Kosten und Komplexität nicht wünschenswert.23

4.1.2 Vorgeschlagene Architektur

Um die Vorteile beider Welten zu kombinieren, wird die Implementierung von Keycloak, einer leistungsstarken Open-Source-IAM-Lösung, als zentraler Identity Broker vorgeschlagen. Keycloak wird über seinen integrierten LDAP/AD-Connector mit dem On-Premise Active Directory föderiert.25 In dieser Konfiguration bleibt AD die maßgebliche Quelle (Source of Truth) für Benutzeridentitäten, während Keycloak als moderne Authentifizierungs- und Autorisierungsfassade für das RAG-System und andere neue Anwendungen dient.

4.1.3 Vorteile des Modells

Dieser hybride Ansatz bietet entscheidende Vorteile:
●	Moderne Protokolle: Das RAG-System kann standardisierte, sichere und API-freundliche Protokolle wie OpenID Connect (OIDC) und OAuth 2.0 nutzen, die von Keycloak nativ unterstützt werden.25
●	Investitionsschutz: Die bestehende AD-Infrastruktur und die damit verbundenen administrativen Prozesse bleiben erhalten. Eine kostspielige und disruptive "Rip-and-Replace"-Migration wird vermieden.
●	Zentralisierte Kontrolle: Keycloak ermöglicht die zentrale Verwaltung von Single Sign-On (SSO), Multi-Faktor-Authentifizierung (MFA) und feingranularen Autorisierungsrichtlinien für alle angebundenen Anwendungen, was die Sicherheit und Benutzerfreundlichkeit erhöht.25

Tabelle 1: Vergleichende Analyse von IAM-Lösungen für eine hybride Umgebung

Die Entscheidung für eine IAM-Strategie ist von strategischer Bedeutung. Die folgende Tabelle vergleicht die drei Hauptalternativen – reines On-Premise AD, cloud-natives Microsoft Entra ID und der vorgeschlagene hybride Ansatz mit Keycloak – anhand von Kriterien, die für das Verwaltungsumfeld entscheidend sind.

Kriterium	On-Premise Active Directory (AD)	Microsoft Entra ID (Cloud)	Keycloak (Hybrid mit AD-Federation)
Architektur	On-Premise, domänencontroller-basiert 22	Cloud-nativ, mandantenbasiert, keine DCs 22	On-Premise, flexibel einsetzbar (VM, Container) 24
Primäre Protokolle	Kerberos, NTLM, LDAP 21	OIDC, OAuth 2.0, SAML 22	OIDC, OAuth 2.0, SAML 25
Verwaltungsmodell	Gruppenrichtlinien (GPOs) für Windows-Geräte 22	Microsoft Intune für plattformübergreifendes MDM 22	Unabhängig vom Gerätemanagement; Fokus auf Anwendungs-IAM
Datenhoheit	Vollständig: Alle Identitätsdaten verbleiben On-Premise.	Eingeschränkt: Identitätsdaten werden in der Microsoft Cloud gespeichert.	Vollständig: Keycloak wird On-Premise betrieben, Daten verbleiben unter eigener Kontrolle.
Kostenmodell	CAPEX (Windows Server Lizenzen, CALs) 22	OPEX (Abonnement-basiert, pro Benutzer/Monat) 22	CAPEX/OPEX (Keine Lizenzkosten, aber Betriebs- und Wartungsaufwand) 27
Komplexität	Hoch bei Integration mit modernen Apps; etablierte Verwaltung.	Hohe Komplexität der Benutzeroberfläche; erfordert Cloud-Expertise.22	Hohe initiale Konfigurations- und Betriebskomplexität.29
Eignung für RAG	Gering: Veraltete Protokolle, keine native API-Sicherheit.	Hoch (technisch): Moderne Protokolle, aber Bedenken bei Datenhoheit.	Optimal: Kombiniert moderne Protokolle mit On-Premise-Kontrolle.
Diese Analyse rechtfertigt die Empfehlung für das hybride Keycloak-Modell als optimalen Kompromiss, der moderne Sicherheitsfunktionen ermöglicht und gleichzeitig die grundlegenden Anforderungen der öffentlichen Verwaltung an Kontrolle und Souveränität erfüllt.

4.2 Dienstidentität: Sicherung der Maschine-zu-Maschine-Kommunikation mit gMSAs und Kerberos


4.2.1 Anwendungsfall und Mechanismus

Für die sichere Kommunikation zwischen Diensten, die auf Windows-Servern innerhalb der AD-Domäne laufen (z.B. der Orchestrierungsdienst, der auf eine Microsoft SQL Server-Datenbank zugreift), wird der Einsatz von Group Managed Service Accounts (gMSAs) empfohlen.31 gMSAs sind spezielle Domänenkonten für Dienste, deren Passwörter nicht manuell verwaltet werden müssen. Active Directory übernimmt automatisch die Generierung hochkomplexer Passwörter und deren regelmäßige Rotation (standardmäßig alle 30 Tage), was das Risiko von Kompromittierungen durch gestohlene oder schwache Dienstkonto-Passwörter drastisch reduziert.32

4.2.2 Authentifizierungsablauf mit Kerberos

Die Authentifizierung von Diensten, die gMSAs verwenden, erfolgt über das Kerberos-Protokoll. Dieser Prozess gewährleistet eine starke, gegenseitige Authentifizierung, ohne dass jemals Passwörter über das Netzwerk übertragen werden.35 Der Ablauf ist wie folgt:
1.	Anforderung des Ticket-Granting Ticket (TGT): Der Client-Dienst (z.B. der Orchestrator) authentifiziert sich beim Authentication Server (AS), einer Komponente des Key Distribution Center (KDC) auf einem Domänencontroller, und fordert ein TGT an.
2.	Anforderung des Dienst-Tickets: Der Client-Dienst verwendet das erhaltene TGT, um beim Ticket-Granting Server (TGS), der zweiten Komponente des KDC, ein Dienst-Ticket für den Zieldienst (z.B. die SQL-Datenbank) anzufordern.
3.	Gegenseitige Authentifizierung: Der Client-Dienst präsentiert das Dienst-Ticket dem Zieldienst. Der Zieldienst kann das Ticket entschlüsseln (da es mit seinem eigenen geheimen Schlüssel verschlüsselt ist) und damit die Identität des Clients verifizieren. Der Prozess ermöglicht auch dem Client, die Identität des Servers zu überprüfen.39

4.2.3 Implementierungsvoraussetzungen

Die erfolgreiche Implementierung von gMSAs erfordert eine korrekte Konfiguration der Active Directory-Umgebung. Dazu gehören die Erstellung eines KDS Root Key, der für die sichere Passwortverwaltung notwendig ist, und die Sicherstellung, dass die Domänen- und Gesamtstruktur-Funktionsebene mindestens auf Windows Server 2012 oder höher eingestellt ist.31

4.3 Sicherung der API- und Microservice-Kommunikation mit mTLS


4.3.1 Mandat für mTLS

Für jegliche interne Kommunikation zwischen Diensten, die nicht auf dem Windows/Kerberos-Stack basiert – insbesondere zwischen dem Orchestrierungsdienst und den Linux-basierten Komponenten wie dem Ollama LLM-Dienst und der Neo4j-Datenbank – ist die Verwendung von mutual TLS (mTLS) zwingend erforderlich.41

4.3.2 Mechanismus und Vorteile in ZTA

Bei Standard-TLS authentifiziert sich nur der Server gegenüber dem Client. Bei mTLS hingegen präsentieren beide Kommunikationspartner – der Client und der Server – ein TLS-Zertifikat und beweisen kryptografisch, dass sie im Besitz des zugehörigen privaten Schlüssels sind.43 Dieser Prozess der gegenseitigen Authentifizierung findet während des TLS-Handshakes statt, noch bevor irgendwelche Anwendungsdaten ausgetauscht werden.
In einer Zero-Trust-Architektur ist mTLS ein Eckpfeiler zur Verhinderung von Spoofing- und On-Path-Angriffen. Es stellt sicher, dass nur verifizierte und vertrauenswürdige Dienste miteinander kommunizieren können. Dies ist fundamental für die Durchsetzung der Netzwerk-Mikrosegmentierung und die Verhinderung lateraler Bewegungen im Falle einer Kompromittierung einer einzelnen Komponente.42

4.3.3 Management der Public Key Infrastructure (PKI)

Die Implementierung von mTLS erfordert die Verwaltung einer internen Public Key Infrastructure (PKI). Dies bringt einen erheblichen operativen Aufwand mit sich. Es wird empfohlen, eine interne Zertifizierungsstelle (Certificate Authority, CA) aufzubauen und Werkzeuge für das automatisierte Management des Zertifikatslebenszyklus (Ausstellung, Erneuerung, Widerruf) einzusetzen, um diesen Aufwand zu bewältigen und die Skalierbarkeit zu gewährleisten.
Die vorgeschlagene dreistufige Identitätsstrategie (Keycloak für Benutzer, gMSA/Kerberos für Windows-Dienste, mTLS für Microservices) schafft ein "Defense-in-Depth"-Modell für die Identität, führt aber auch eine erhebliche Integrationskomplexität ein. Die zentrale Herausforderung besteht darin, eine konsistente Richtliniendurchsetzung über diese unterschiedlichen Identitätsdomänen hinweg sicherzustellen. Eine Anfrage eines Benutzers, die von Keycloak authentifiziert wird, löst eine Kette interner Dienstaufrufe aus, die jeweils durch Kerberos oder mTLS authentifiziert werden. Die Autorisierungsentscheidung muss über diese gesamte Kette hinweg konsistent bleiben. Wenn ein Benutzer beispielsweise nur Daten der "Abteilung A" sehen darf, muss jeder Dienst in der Kette in der Lage sein, diese Einschränkung zu überprüfen und durchzusetzen. Dies ist nicht möglich, wenn Identitäts- und Autorisierungsinformationen an den Grenzen zwischen diesen Systemen verloren gehen. Daher ist eine kritische Designanforderung die sichere Weitergabe der Identität und des Autorisierungskontexts des ursprünglichen Benutzers (z.B. in einem signierten JWT) durch die gesamte interne Dienstaufrufkette. Mit mTLS oder Kerberos authentifizierte Dienste müssen dieses JWT empfangen, validieren und seine Claims verwenden, um ihre eigenen feingranularen Autorisierungsentscheidungen zu treffen. Dieses Muster, bekannt als Identitätsweitergabe (Identity Propagation), ist unerlässlich, um ein durchgängiges Zero-Trust-Modell aufrechtzuerhalten.
________________________________________
Abschnitt 5: Mehrschichtige Daten- und Netzwerksicherheitskontrollen

Nachdem die Identität als Fundament etabliert ist, konzentriert sich die nächste Schicht der Zero-Trust-Architektur auf die strikte Kontrolle des Datenflusses und des Zugriffs auf die Daten selbst. Dies wird durch eine Kombination aus Netzwerk-Mikrosegmentierung und anwendungsorientierten Sicherheitsmechanismen erreicht.

5.1 Netzwerk-Mikrosegmentierung und LLM-Härtung


5.1.1 Prinzip der Mikrosegmentierung

Das Prinzip der Mikrosegmentierung ist eine direkte Konsequenz der "Assume Breach"-Mentalität. Anstatt eines großen, flachen "vertrauenswürdigen" Netzwerks wird die Infrastruktur in kleine, granulare und isolierte Segmente unterteilt, die idealerweise eine einzelne Anwendung oder sogar eine einzelne Komponente enthalten.4 Die Standardrichtlinie für die Kommunikation zwischen diesen Segmenten lautet "Deny All". Nur explizit definierte und absolut notwendige Kommunikationspfade werden über Firewall-Regeln freigegeben. Dies beschränkt die Fähigkeit eines Angreifers, sich nach einer initialen Kompromittierung lateral im Netzwerk zu bewegen, drastisch. Jede Komponente des RAG-Systems – API-Gateway, Orchestrator, LLM-Dienst und jede Datenbank der Wissensbasis – wird in einem eigenen, isolierten Netzwerksegment platziert.

5.1.2 Härtung des Ollama LLM-Dienstes

Der On-Premise LLM-Dienst ist aufgrund seiner Rechenintensität und der Sensitivität des Modells ein besonders kritisches Asset. Da Open-Source-Frameworks wie Ollama auf Benutzerfreundlichkeit und nicht primär auf Sicherheit ausgelegt sind, sind spezifische Härtungsmaßnahmen unerlässlich.11
●	Netzwerkisolation: Der Ollama-Dienst darf unter keinen Umständen direkt aus anderen Netzwerken als seinem dedizierten, isolierten Machine-Learning-Subnetz erreichbar sein.11 Die Standardkonfiguration von Ollama kann an
0.0.0.0 binden, was den Dienst auf allen Netzwerkschnittstellen verfügbar macht. Dies muss zwingend so konfiguriert werden, dass der Dienst nur an eine spezifische, interne IP-Adresse des isolierten Subnetzes gebunden ist.47
●	Zugriffskontrolle auf Netzwerkebene: Der Zugriff auf die Ollama-API (standardmäßig Port 11434) muss auf Netzwerkebene (über Firewall-Regeln oder Security Groups) strikt auf die IP-Adresse des Orchestrierungsdienstes beschränkt werden. Alle anderen eingehenden Verbindungen müssen blockiert werden.18
●	Authentifizierungsschicht (Reverse Proxy): Da Ollama standardmäßig keine eigene Authentifizierungsschicht besitzt, muss ein authentifizierender Reverse Proxy (z.B. Nginx oder ein API-Gateway) vor den Dienst geschaltet werden. Dieser Proxy fängt alle Anfragen ab, validiert das Vorhandensein und die Gültigkeit eines Authentifizierungstokens (z.B. ein von Keycloak ausgestelltes JWT) und leitet die Anfrage nur bei erfolgreicher Prüfung an den Ollama-Dienst weiter. Dies fügt eine entscheidende anwendungsspezifische Sicherheitsebene hinzu.47
●	Härtung der Modell-Management-Endpunkte: Die API-Endpunkte für die Verwaltung von Modellen (z.B. /api/pull, /api/create) ermöglichen das Herunterladen oder Erstellen neuer LLM-Modelle. In einer Produktionsumgebung müssen diese Endpunkte entweder vollständig deaktiviert oder durch strenge administrative Berechtigungen geschützt werden, um unautorisierte Modell-Uploads (Modellvergiftung) oder -Downloads (Modelldiebstahl) zu verhindern.20

5.2 Sicherung der RAG-Wissensdatenbank


5.2.1 Sicherheitsarchitektur für polyglotte Persistenz

Der Einsatz mehrerer verschiedener Datenbanktechnologien (polyglotte Persistenz) bietet zwar Performance- und Flexibilitätsvorteile, birgt aber auch erhebliche Sicherheitsrisiken. Jede Datenbank hat ihre eigenen Sicherheitsmodelle, Authentifizierungsmechanismen und Konfigurationsdetails. Der Versuch, die Sicherheit auf der Ebene jeder einzelnen Datenbank zu verwalten, führt unweigerlich zu inkonsistenten Sicherheitskontrollen, Konfigurationsfehlern und Datensilos, die eine ganzheitliche Sicht auf die Datensicherheit unmöglich machen.50
Die strategische Lösung für dieses Problem besteht darin, die primäre Durchsetzung der Sicherheitsrichtlinien von der Datenbankebene auf die Anwendungsebene zu verlagern. Alle Datenzugriffsanfragen, unabhängig von der Zieldatenbank, müssen zwingend durch den zentralen Orchestrierungsdienst fließen. Dieser Dienst agiert als Policy Enforcement Point (PEP) für Daten. Er ist dafür verantwortlich, für jede Anfrage konsistente Authentifizierungs-, Autorisierungs- und Protokollierungsrichtlinien durchzusetzen, bevor er mit dem jeweiligen Datenspeicher interagiert.

5.2.2 Anwendungsorchestrierte dynamische Row-Level Security (RLS)

Ein zentrales Sicherheitsrisiko in einem RAG-System besteht darin, dass ein Benutzer eine allgemeine Frage stellt, aber eine Antwort erhält, die auf Informationen aus Dokumenten basiert, für die er keine Zugriffsberechtigung hat. Um dies zu verhindern, muss sichergestellt werden, dass der für den LLM-Prompt abgerufene Kontext ausschließlich Daten enthält, die der anfragende Benutzer sehen darf.
Dies wird durch eine anwendungsorchestrierte, dynamische Row-Level Security (RLS) erreicht. Der Mechanismus wird innerhalb des Orchestrierungsdienstes implementiert und funktioniert wie folgt:
1.	Identitätsvalidierung: Bei Eingang einer Benutzeranfrage validiert der Dienst das JWT des Benutzers, um dessen Identität und Rollen/Gruppenzugehörigkeiten zu überprüfen.
2.	Abruf der Berechtigungen: Der Dienst fragt eine zentrale Berechtigungstabelle in der relationalen Datenbank ab, um die spezifischen Datenzugriffsrechte des Benutzers zu ermitteln (z.B. Benutzer_A darf Daten mit dem Attribut Abteilung='Finanzen' und Sicherheitsstufe='Intern' sehen).
3.	Dynamische Injektion von Filtern: Der Orchestrierungsdienst modifiziert die Abfragen, die er an die zugrunde liegenden Wissensdatenbanken sendet, dynamisch. Er fügt die aus Schritt 2 ermittelten Berechtigungen als zusätzliche Filterprädikate in die Abfragen ein.51 Eine Vektorsuche wird beispielsweise so angepasst, dass sie nur innerhalb von Dokumenten sucht, die mit den entsprechenden Metadaten (
Abteilung='Finanzen', Sicherheitsstufe='Intern') getaggt sind.
Dieser Ansatz zentralisiert die Zugriffslogik und ist technologieunabhängig, was ihn ideal für eine polyglotte Datenbankumgebung macht. Er überwindet die Einschränkungen nativer RLS-Implementierungen, die oft nicht in allen Datenbanktypen verfügbar oder konsistent sind.54

5.2.3 Granulare Zugriffskontrolle für Neo4j durch AD-Integration

Als zusätzliche "Defense-in-Depth"-Maßnahme wird die Neo4j-Graphdatenbank direkt mit dem Active Directory integriert, um eine datenbankinterne Zugriffskontrolle zu etablieren.
●	Konfiguration: Neo4j wird so konfiguriert, dass es LDAP als Authentifizierungs- und Autorisierungsanbieter verwendet und auf die On-Premise-Domänencontroller verweist.56
●	Rollen-Mapping: Die Konfigurationseinstellung dbms.security.ldap.authorization.group_to_role_mapping wird verwendet, um spezifische AD-Sicherheitsgruppen (z.B. die Gruppe "Finanzanalysten") direkt auf vordefinierte Rollen innerhalb von Neo4j (z.B. eine Rolle namens "finanz_leser") abzubilden.56
●	Rechtevergabe: Innerhalb von Neo4j werden diesen Rollen mithilfe der Cypher-Abfragesprache feingranulare Berechtigungen zugewiesen. Beispielsweise könnte der Rolle "finanz_leser" nur Lesezugriff auf Knoten mit dem Label :Transaction und Beziehungen des Typs :BELONGS_TO gewährt werden.17 Dies stellt sicher, dass selbst bei einem direkten, unautorisierten Zugriff auf die Datenbank die internen Sicherheitsmechanismen den Datenzugriff weiter einschränken.

Tabelle 2: Zero-Trust-Kontrollmatrix für die RAG-Architektur

Die folgende Matrix bietet eine Übersicht über die Zuordnung der primären und sekundären Sicherheitskontrollen zu den einzelnen Komponenten der RAG-Architektur. Sie dient als Referenz für Architekten, Implementierer und Auditoren, um die praktische Anwendung der ZTA-Prinzipien zu verstehen.
Komponente	Identität/Authentifizierung	Netzwerk-Kontrollen	Datenzugriffs-Kontrollen	Überwachung/Protokollierung
API-Gateway	JWT-Validierung (OIDC)	Ratenbegrenzung, WAF	-	Detaillierte Anfrageprotokollierung
Orchestrator	mTLS (Client), gMSA/Kerberos	Mikrosegmentierung	Dynamische RLS, JWT-Claim-basierte Autorisierung	Protokollierung aller Geschäftslogik- und Datenzugriffsentscheidungen
Ollama LLM-Dienst	mTLS (Server), Reverse-Proxy-Auth	Strikte Isolation, Firewall-Regeln (nur Orchestrator)	Deaktivierte Management-Endpunkte	Protokollierung von Inferenzanfragen
Vektor-DB (Chroma)	mTLS (Server)	Mikrosegmentierung, Firewall-Regeln (nur Orchestrator)	Zugriff nur über Orchestrator (RLS-gefiltert)	Protokollierung aller DB-Abfragen
Graph-DB (Neo4j)	mTLS (Server), AD/LDAP-Integration	Mikrosegmentierung, Firewall-Regeln (nur Orchestrator)	AD-Gruppen-basiertes RBAC, Zugriff nur über Orchestrator (RLS-gefiltert)	Detaillierte Audit-Protokollierung
Relationale DB (SQL)	gMSA/Kerberos	Mikrosegmentierung, Firewall-Regeln (nur Orchestrator)	Zugriff nur über Orchestrator, Speicherung von Berechtigungsdaten	Detaillierte Audit-Protokollierung
________________________________________
Abschnitt 6: Prozessintegrität in verteilten Systemen: Das Saga-Pattern


6.1 Die Konsequenz der Dezentralisierung: Verteilte Transaktionen

Die strategische Entscheidung für eine moderne, resiliente IT-Architektur, die auf Microservices und Polyglot Persistence basiert, hat eine unausweichliche Konsequenz: Ein einzelner, zusammenhängender Geschäftsprozess erstreckt sich nun über die Grenzen mehrerer Dienste und deren unabhängiger Datenbanken hinweg.69 Dies schafft die fundamentale Herausforderung der verteilten Transaktion: Wie kann sichergestellt werden, dass der gesamte, mehrstufige Prozess entweder vollständig erfolgreich abgeschlossen wird oder im Fehlerfall sauber und ohne inkonsistente Daten zurückgelassen wird?.69

6.2 Die Untauglichkeit traditioneller Protokolle (2PC)

In der Welt monolithischer Datenbanken wurde dieses Problem durch Protokolle wie den Two-Phase Commit (2PC) gelöst. Für moderne, verteilte Architekturen ist 2PC jedoch aus mehreren Gründen ungeeignet: Es ist von Natur aus blockierend und reduziert die Performance, der Koordinator stellt einen zentralen Ausfallpunkt dar, und entscheidend ist, dass viele moderne NoSQL-Datenbanken das 2PC-Protokoll schlichtweg nicht unterstützen.69

6.3 Das Saga-Pattern als Lösung

Die moderne Antwort auf diese Herausforderung ist das Saga-Pattern. Eine Saga definiert einen komplexen Geschäftsprozess als eine Sequenz von lokalen Transaktionen.69 Jede dieser Transaktionen wird innerhalb eines einzelnen Dienstes ausgeführt und ist in sich atomar. Die entscheidende Innovation ist der Umgang mit Fehlern durch
kompensierende Transaktionen. Wenn ein Schritt in der Saga fehlschlägt, ist die Saga dafür verantwortlich, für alle bereits erfolgreich abgeschlossenen Schritte eine entsprechende "Rückgängig"-Aktion auszuführen, um das Gesamtsystem wieder in einen konsistenten Zustand zu versetzen.69 Dieser Ansatz bietet keine strikte ACID-Isolation, sondern garantiert eventuelle Konsistenz, ein bewusster architektonischer Kompromiss zugunsten von loser Kopplung und höherer Verfügbarkeit.69

6.4 Governance-Modelle: Orchestrierung vs. Choreographie

Es gibt zwei grundlegend verschiedene Modelle zur Koordination einer Saga 69:
●	Saga-Orchestrierung: Ein zentraler Dienst, der Orchestrator, agiert als Dirigent des gesamten Prozesses. Er sendet explizite Befehle an die einzelnen Dienste und steuert im Fehlerfall die kompensierenden Transaktionen. Die gesamte Prozesslogik ist an diesem zentralen Ort konzentriert.69
●	Saga-Choreographie: Es gibt keinen zentralen Koordinator. Jeder Dienst reagiert auf Ereignisse, die von anderen Diensten veröffentlicht werden. Die Prozesslogik ist über alle teilnehmenden Dienste verteilt.69

6.5 Mandat der Auditierbarkeit: Warum Orchestrierung der Standard ist

Im Kontext der öffentlichen Verwaltung ist die Saga-Orchestrierung die einzig verantwortbare Wahl. Der Grund dafür ist das übergeordnete Prinzip der Rechtssicherheit, das eine lückenlose, unzweideutige und leicht nachvollziehbare Auditierbarkeit aller Verwaltungsvorgänge erfordert.69 Das Transaktionsprotokoll (Saga Log) eines Orchestrators dient als definitiver, gerichtsverwertbarer Nachweis über den exakten Ablauf eines Verfahrens. Es dokumentiert explizit jeden ausgeführten Schritt, jede Entscheidung und jede Kompensation.69 Die Rekonstruktion eines Prozesses in einer choreographierten Saga ist hingegen extrem aufwendig und macht es nahezu unmöglich, einen für Dritte (z. B. ein Gericht) verständlichen Nachweis zu erbringen. Diese mangelnde explizite Nachvollziehbarkeit ist ein fataler Mangel für rechtlich relevante Verwaltungsprozesse.69
________________________________________
Abschnitt 7: Dynamische Richtliniendurchsetzung und kontinuierliche Überwachung

Eine statische, einmalig definierte Sicherheitsrichtlinie ist in der heutigen Bedrohungslandschaft unzureichend. Eine Kernkomponente der Zero-Trust-Architektur ist die Fähigkeit, Zugriffsentscheidungen dynamisch und in Echtzeit zu treffen, basierend auf einem breiten Spektrum an kontextbezogenen Informationen. Dies wird durch eine kontinuierliche Überwachung und Analyse aller relevanten System- und Benutzeraktivitäten ermöglicht.

7.1 Implementierung von Echtzeit-Zugriffsrichtlinien


7.1.1 Dynamische Entscheidungsfindung

Der Policy Decision Point (PDP), der logisch im API-Gateway und im Orchestrierungsdienst implementiert ist, muss über die reine Überprüfung statischer Rollen hinausgehen. Jede Zugriffsentscheidung wird zu einer dynamischen Risikobewertung, die auf einer Vielzahl von kontextbezogenen Daten und Signalen basiert.7 Anstatt der einfachen Frage "Ist dieser Benutzer in der richtigen Rolle?", stellt der PDP die Frage "Sollte dieser Benutzer von diesem Gerät an diesem Ort zu dieser Zeit auf diese Ressource zugreifen dürfen?".

7.1.2 Integration von Signalen

Um diese fundierten Entscheidungen treffen zu können, muss der PDP Signale aus verschiedenen Quellen in Echtzeit synthetisieren und bewerten:
●	Identitätsanbieter (Keycloak): Liefert grundlegende Informationen wie die verifizierte Benutzeridentität, Gruppenzugehörigkeiten und die Stärke der durchgeführten Authentifizierung (z.B. ob eine Multi-Faktor-Authentifizierung (MFA) verwendet wurde).
●	Geräteverwaltung (Mobile Device Management, MDM): Stellt Informationen über den Sicherheitszustand des zugreifenden Geräts bereit. Ist das Betriebssystem auf dem neuesten Stand? Ist die Festplattenverschlüsselung aktiv? Ist eine Antiviren-Software installiert und aktuell? Ein Gerät, das diese Kriterien nicht erfüllt, stellt ein höheres Risiko dar.
●	Ressourcensensitivität: Die angeforderte Ressource oder Information selbst ist ein entscheidender Kontextfaktor. Der Zugriff auf öffentlich klassifizierte Informationen ist weniger riskant als der Zugriff auf als "Vertraulich" oder "Geheim" eingestufte Dokumente.
●	Verhaltensanalytik (User and Entity Behavior Analytics, UEBA): Ein UEBA-System analysiert kontinuierlich die Aktivitäten von Benutzern und Diensten, um eine Baseline für normales Verhalten zu erstellen. Jede signifikante Abweichung von dieser Baseline (z.B. ein Benutzer, der plötzlich auf Daten zugreift, mit denen er noch nie interagiert hat; ein Login von einem geografisch unmöglichen Ort; ungewöhnlich hohe Daten-Download-Raten) wird als Anomalie gemeldet und fließt als Risikosignal in die PDP-Entscheidung ein.
Eine effektive dynamische Richtliniendurchsetzung hängt entscheidend von einem ausgereiften Datenklassifizierungsschema ab. Das System kann keine risikobasierten Entscheidungen treffen, wenn es die Sensitivität der Daten, auf die zugegriffen wird, nicht kennt. Die ZTA ist somit auf ein grundlegendes Data-Governance-Programm angewiesen. ZTA-Richtlinien sind kontextbewusst und dynamisch 7, und einer der wichtigsten Kontextfaktoren ist die Sensitivität der Ressource. Der Zugriff auf öffentliche Informationen ist ein geringes Risiko, während der Zugriff auf Verschlusssachen ein hohes Risiko darstellt. Die Wissensdatenbank des RAG-Systems wird Daten unterschiedlicher Sensitivitätsstufen enthalten. Um eine risikobasierte Zugriffskontrolle zu implementieren (z.B. die Anforderung von MFA nur für hochsensible Daten), muss jedes Dokument in der Wissensdatenbank mit einer Klassifizierungsstufe versehen sein. Dies ist keine Sicherheitsaufgabe, sondern eine Aufgabe der Data Governance. Sie erfordert, dass die Facheigentümer definieren, was sensibel ist, und einen Prozess zur Kennzeichnung neuer Daten bei deren Aufnahme implementieren. Daher ist der Erfolg der ZTA-Implementierung direkt von der Reife des Data-Governance-Programms der Organisation abhängig. Dieses Strategiedokument muss diese Abhängigkeit hervorheben und eine parallele Initiative zur Etablierung oder Weiterentwicklung von Datenklassifizierungsstandards empfehlen.

7.2 Umfassende Auditierbarkeit und Integration von Bedrohungsinformationen


7.2.1 Zentralisierte Protokollierung

Ein Grundpfeiler von Zero Trust ist die vollständige Transparenz und Nachvollziehbarkeit. Jede Komponente der RAG-Architektur muss detaillierte, strukturierte Protokolle für jede einzelne Zugriffsanfrage, jede administrative Aktion und jeden signifikanten Systemzustand exportieren. Diese Protokolle werden an ein zentrales Security Information and Event Management (SIEM)-System gesendet. Dies schafft einen lückenlosen und unveränderlichen Audit-Trail, der für forensische Analysen, Compliance-Nachweise und die Echtzeit-Überwachung unerlässlich ist.1

7.2.2 Anreicherung mit Threat Intelligence

Das SIEM-System reichert die eingehenden Protokolldaten automatisch mit externen und internen Threat-Intelligence-Feeds an. Dies ermöglicht es, scheinbar harmlose Ereignisse in einen größeren Bedrohungskontext zu stellen. Beispielsweise kann eine Zugriffsanfrage von einer IP-Adresse, die in einem Threat-Feed als Teil eines bekannten Botnetzes aufgeführt ist, sofort als hochriskant eingestuft werden.4 Die Integration von Informationen über die neuesten Zero-Day-Exploits kann dabei helfen, betroffene Systeme proaktiv zu identifizieren.

7.2.3 Automatisierte Reaktion

Die Kombination aus zentralisierter Protokollierung, Verhaltensanalytik und Threat-Intelligence-Anreicherung ermöglicht eine schnelle und sogar automatisierte Reaktion auf erkannte Bedrohungen. Das SIEM kann so konfiguriert werden, dass es bei hochgradig verdächtigen oder eindeutig bösartigen Aktivitäten automatisierte Reaktionen (sogenannte "SOAR"-Playbooks - Security Orchestration, Automation, and Response) auslöst. Beispiele hierfür sind:
●	Das sofortige Widerrufen der aktuellen Sitzung eines Benutzers.
●	Das temporäre Sperren eines Benutzerkontos.
●	Das automatische Hinzufügen einer blockierenden Firewall-Regel, um ein kompromittiertes System vom Netzwerk zu isolieren.
Diese Automatisierung verkürzt die Reaktionszeit von Stunden oder Tagen auf Sekunden und ist entscheidend, um den Schaden einer laufenden Kompromittierung zu minimieren.
________________________________________
Abschnitt 8: Leistung, Skalierbarkeit und sicherer Entwicklungslebenszyklus

Die Implementierung einer Zero-Trust-Architektur ist kein Selbstzweck; sie muss die Leistungs- und Skalierbarkeitsanforderungen des RAG-Systems erfüllen und sich nahtlos in einen sicheren Entwicklungslebenszyklus (Secure SDLC) integrieren lassen. Eine sorgfältige Analyse und Planung dieser Aspekte ist entscheidend für den Erfolg des Projekts.

8.1 Analyse des Performance-Overheads

Es ist eine unbestreitbare Tatsache, dass die kontinuierliche Verifizierung, die das Herzstück von Zero Trust bildet, einen gewissen Performance-Overhead in Form von Latenz mit sich bringt. Jede Authentifizierung, jede Autorisierungsprüfung und jede kryptografische Operation benötigt Zeit. Das Ziel ist nicht, diesen Overhead zu eliminieren, was unmöglich wäre, sondern ihn durch intelligente architektonische Entscheidungen und gezielte Optimierungen auf ein für den Benutzer und das System akzeptables Niveau zu reduzieren und zu managen.3

8.1.1 Latenz bei der JWT-Validierung

Die Validierung von JSON Web Tokens (JWTs) ist eine Kernoperation bei jeder API-Anfrage. Die Wahl des kryptografischen Algorithmus hat hier einen dramatischen Einfluss auf die Performance.
●	Asymmetrische Algorithmen (z.B. RS256): Diese verwenden ein Schlüsselpaar (öffentlich/privat) und sind rechenintensiv. Benchmarks und Fallstudien zeigen, dass die Signierung und Verifizierung mit RSA-2048 oder RSA-4096 erhebliche Latenz verursachen kann. Eine Studie berichtete von einer Latenz von ca. 251 ms allein für die Signierungsoperation.59 Während ein moderner CPU-Kern Zehntausende von Verifizierungen pro Sekunde durchführen kann, kann dies bei sehr hohem Anfragevolumen zu einem signifikanten Engpass werden.60
●	Symmetrische Algorithmen (z.B. HS256): Diese verwenden einen einzigen, geteilten geheimen Schlüssel (Shared Secret) und sind um Größenordnungen schneller. Die kryptografischen Operationen (HMAC) sind weitaus weniger CPU-intensiv, und die Latenz für die Verifizierung liegt typischerweise im Bereich von unter einer Millisekunde.59
Empfehlung: Für die interne Service-zu-Service-Kommunikation, bei der der geheime Schlüssel sicher zwischen den Diensten verwaltet werden kann (z.B. über ein Secret-Management-System), sollte zwingend der symmetrische Algorithmus HS256 verwendet werden. Der asymmetrische Algorithmus RS256 sollte für Tokens reserviert bleiben, die von externen Parteien verifiziert werden müssen, denen man den geheimen Schlüssel nicht anvertrauen kann.59

8.1.2 Latenz des mTLS-Handshakes

Die gegenseitige TLS-Authentifizierung (mTLS) fügt dem initialen Verbindungsaufbau ebenfalls Latenz hinzu. Der vollständige Handshake erfordert zusätzliche Netzwerk-Round-Trips für den Austausch und die Verifizierung der Client- und Server-Zertifikate sowie rechenintensive kryptografische Operationen.44 Bei Anwendungen mit hohem Transaktionsvolumen und kurzlebigen Verbindungen kann sich dieser Overhead akkumulieren und zu spürbaren Verlangsamungen führen.
Empfehlung: Um diesen Overhead zu mitigieren, müssen zwingend Mechanismen zur Wiederverwendung von Sitzungen implementiert werden.
●	TLS Session Resumption: Techniken wie Session Tickets oder Session IDs ermöglichen es einem Client, eine frühere TLS-Sitzung mit einem Server schnell wieder aufzunehmen, ohne den vollständigen kryptografischen Handshake erneut durchführen zu müssen.
●	Connection Pooling: Anstatt für jede Anfrage eine neue Verbindung aufzubauen, werden bestehende, bereits authentifizierte und verschlüsselte Verbindungen in einem Pool gehalten und für nachfolgende Anfragen wiederverwendet.
Die Kombination dieser beiden Techniken reduziert die Latenz für die überwiegende Mehrheit der Anfragen dramatisch, da der teure mTLS-Handshake nur einmal pro Verbindungsserie stattfindet.45

Tabelle 3: Latenzauswirkungen und Mitigation für ZTA-Sicherheitskontrollen

Entscheidungsträger werden Bedenken hinsichtlich der Leistungsauswirkungen von ZTA auf ein Echtzeit-KI-System haben. Die Bereitstellung konkreter, quantitativer Daten aus Benchmarks und Forschungsergebnissen zeigt ein tiefes Verständnis des Problems und schafft Vertrauen in die vorgeschlagenen Lösungen. Die folgende Tabelle quantifiziert die erwartete Latenz und schreibt Lösungen vor, um ein abstraktes Anliegen ("Performance") in ein beherrschbares technisches Problem mit klaren Lösungen zu verwandeln.

Sicherheitskontrolle	Typische Latenz-Overhead	Einflussfaktor	Primäre Mitigationsstrategie
JWT-Validierung (RS256)	> 10 ms (potenziell > 200 ms bei Signierung) 59	CPU-Auslastung (asymmetrische Kryptografie)	Algorithmische Auswahl: Nur für externe Validierung verwenden.
JWT-Validierung (HS256)	< 1 ms 61	CPU-Auslastung (symmetrische Kryptografie)	Standard für interne Kommunikation
mTLS-Handshake (Initial)	2-4 Netzwerk-Round-Trips + CPU-Last 45	Netzwerk-Latenz, CPU-Auslastung	Minimieren: Nur für neue Verbindungen erforderlich.
mTLS-Handshake (Resumed)	1 Netzwerk-Round-Trip 45	Netzwerk-Latenz	TLS Session Resumption, Connection Pooling

8.2 Sichere Entwicklungs- und Betriebsmuster


8.2.1 Strategy Design Pattern für die Authentifizierung

Problemstellung: In Entwicklungs- und Testumgebungen ist es oft unpraktikabel, unsicher oder schlicht unmöglich, eine Verbindung zum produktiven Identitätsanbieter (AD/Keycloak) herzustellen. Entwickler benötigen jedoch eine Möglichkeit, verschiedene Benutzerrollen und Berechtigungsszenarien zu testen. Das vollständige Deaktivieren der Sicherheit für Testzwecke ist ein gefährliches Anti-Pattern, das dazu führt, dass sicherheitsrelevanter Code nicht getestet wird.
Lösung: Die Authentifizierungs- und Autorisierungslogik im Orchestrierungsdienst sollte nach dem "Strategy"-Entwurfsmuster implementiert werden.63
Mechanismus:
1.	Definition einer Schnittstelle: Es wird eine gemeinsame Schnittstelle (Interface) AuthenticationProvider definiert, die Methoden wie authenticate(request) und getPermissions(user) vorschreibt.
2.	Erstellung konkreter Strategien: Für jede Umgebung wird eine konkrete Klasse erstellt, die diese Schnittstelle implementiert:
○	KeycloakAuthenticationProvider: Die Implementierung für die Produktionsumgebung. Sie kommuniziert mit Keycloak, validiert OIDC-Tokens und ruft Benutzerinformationen ab.
○	MockAuthenticationProvider: Eine Implementierung für Entwicklungs- und Testumgebungen. Diese Klasse stellt keine Verbindung zu einem externen System her. Stattdessen liest sie Benutzerinformationen und Berechtigungen aus einer einfachen Konfigurationsdatei oder gibt hartcodierte Werte zurück. Sie ermöglicht es Entwicklern, jeden beliebigen Benutzer und jede Rolle zu simulieren, ohne echte Anmeldeinformationen zu benötigen.65
3.	Dynamische Auswahl der Strategie: Die Anwendung wählt zur Laufzeit, welche Implementierung des AuthenticationProvider sie verwendet, basierend auf einer Umgebungsvariable oder einer Konfigurationseinstellung.
Vorteile: Dieses Muster entkoppelt die Anwendungslogik sauber vom spezifischen Authentifizierungsmechanismus. Es ermöglicht robuste, sichere und isolierte Tests von sicherheitskritischen Pfaden im Code und stellt gleichzeitig sicher, dass in der Produktionsumgebung die vollständig gehärtete Implementierung verwendet wird.67
________________________________________
Abschnitt 9: Gestufter Implementierungsfahrplan und strategische Empfehlungen

Die Einführung einer umfassenden Zero-Trust-Architektur ist ein komplexes Unterfangen, das eine sorgfältige Planung und eine schrittweise Umsetzung erfordert. Ein "Big Bang"-Ansatz ist zum Scheitern verurteilt. Stattdessen wird ein gestufter Fahrplan vorgeschlagen, der es ermöglicht, schrittweise Fähigkeiten aufzubauen, Risiken zu managen und frühzeitig Erfolge zu erzielen.

9.1 Gestufter Implementierungsansatz


9.1.1 Phase 1: Fundament (Monate 1-3)

In dieser ersten Phase werden die grundlegenden Bausteine der Architektur gelegt, ohne das bestehende System direkt zu beeinflussen.
●	Aufbau der IAM-Infrastruktur: Installation, Konfiguration und Härtung der Keycloak-Instanz in einer hochverfügbaren Konfiguration. Einrichtung der User Federation mit dem bestehenden Active Directory, um Benutzeridentitäten zu synchronisieren oder abzurufen.
●	Entwicklung des Datenklassifizierungsschemas: In Zusammenarbeit mit den Fachabteilungen wird ein verbindliches Schema zur Klassifizierung von Daten (z.B. Öffentlich, Intern, Vertraulich, Geheim) entwickelt. Es wird ein Prozess zur Kennzeichnung kritischer, bestehender Datenquellen initiiert.
●	Bereitstellung der zentralen Protokollierungsplattform: Implementierung des zentralen SIEM-Systems. Konfiguration der grundlegenden Log-Quellen und Einrichtung der Infrastruktur für die Sammlung und Speicherung von Audit-Daten.

9.1.2 Phase 2: Erstbereitstellung & Netzwerkkontrollen (Monate 4-6)

In dieser Phase wird eine erste, nicht-produktive Version des RAG-Systems in einer kontrollierten Umgebung bereitgestellt, um die grundlegenden Netzwerksicherheitskontrollen zu implementieren und zu testen.
●	Pilot-Deployment des RAG-Systems: Bereitstellung aller RAG-Komponenten (Orchestrator, Ollama, Datenbanken) in einer vollständig mikrosegmentierten Netzwerkumgebung.
●	Implementierung der Netzwerkrichtlinien: Definition und Durchsetzung der grundlegenden Firewall-Regeln nach dem "Deny All"-Prinzip. Härtung des Ollama-Dienstes gemäß den in Abschnitt 5.1.2 definierten Maßnahmen.
●	Einführung von mTLS: Implementierung von mTLS für die gesamte Service-zu-Service-Kommunikation. Dies beinhaltet den Aufbau der internen PKI und die Automatisierung der Zertifikatsausstellung für die Dienste.

9.1.3 Phase 3: Anwendungsorientierte Kontrollen & Überwachung (Monate 7-9)

Der Fokus verlagert sich nun auf die Implementierung der anwendungsspezifischen Sicherheitslogik und die Aktivierung der Überwachungs- und Analysefunktionen.
●	Implementierung des Saga-Orchestrators und der UDS3-Schicht: Entwicklung und Integration des zentralen Saga-Orchestrators zur Steuerung der verteilten Geschäftsprozesse. Implementierung der UDS3-Adapterschicht für die polyglotte Persistenz.69
●	Implementierung der anwendungsorchestrierten RLS: Entwicklung und Integration der Logik für die dynamische Row-Level Security in den Orchestrierungsdienst.
●	Integration mit dem SIEM: Anbindung aller RAG-Komponenten an das zentrale SIEM. Aufbau der ersten Monitoring-Dashboards und Konfiguration von grundlegenden Alarmen für kritische Sicherheitsereignisse (z.B. fehlgeschlagene Authentifizierungen, unautorisierte Zugriffsversuche).
●	Konfiguration der Neo4j-AD-Integration: Umsetzung des Rollen-Mappings zwischen Active Directory-Gruppen und Neo4j-Rollen zur Etablierung der "Defense-in-Depth"-Kontrolle auf Datenbankebene.

9.1.4 Phase 4: Optimierung und Erweiterung (Monate 10-12)

In der letzten Phase wird das System für den produktiven Einsatz optimiert, und die etablierten Muster werden auf andere Bereiche ausgeweitet.
●	Durchführung von Leistungstests: Systematische Last- und Leistungstests, um Engpässe zu identifizieren. Implementierung von Performance-Optimierungen wie TLS Session Resumption und Connection Pooling.
●	Integration dynamischer Signale: Anbindung der Policy Engine an die Geräteverwaltung und das UEBA-System, um dynamische, risikobasierte Zugriffsentscheidungen zu ermöglichen.
●	Erweiterung des ZTA-Frameworks: Planung der Übertragung der etablierten Zero-Trust-Muster und der aufgebauten Infrastruktur (Keycloak, SIEM) auf weitere kritische Anwendungen innerhalb der Verwaltung.

9.2 Kritische strategische Empfehlungen

Die technologische Implementierung allein garantiert nicht den Erfolg. Sie muss von strategischen organisatorischen Entscheidungen begleitet werden.
●	Investition in ein dediziertes IAM-Team: Die Komplexität der Verwaltung einer hybriden Keycloak/AD-Umgebung, einer PKI für mTLS und der feingranularen Autorisierungsrichtlinien erfordert spezialisiertes und tiefgehendes Fachwissen. Die Bereitstellung von Ressourcen für ein dediziertes Team, das für den Betrieb und die Weiterentwicklung der IAM-Plattform verantwortlich ist, ist unerlässlich.
●	Priorisierung der Data Governance: Die Wirksamkeit dynamischer Zugriffskontrollen wie RLS steht und fällt mit der Qualität der Datenklassifizierung. Data Governance darf kein Nebenschauplatz sein, sondern muss als paralleles, hochpriorisiertes Projekt vorangetrieben werden. Ohne eine klare und durchgängige Kennzeichnung der Datensensitivität bleiben die fortschrittlichsten Sicherheitskontrollen wirkungslos.
●	Automatisierung als Schlüssel zur Skalierbarkeit: Der manuelle Verwaltungsaufwand einer Zero-Trust-Umgebung ist immens. Die Automatisierung von Prozessen wie der Richtlinienbereitstellung (Policy as Code), dem Zertifikatsmanagement und der Compliance-Überprüfung ist entscheidend, um die Komplexität zu beherrschen, menschliche Fehler zu reduzieren und das System skalierbar zu machen.
●	Etablierung einer Kultur der kontinuierlichen Verbesserung: Zero Trust ist kein einmaliges Projekt, das nach 12 Monaten abgeschlossen ist. Es ist ein kontinuierlicher Prozess der Anpassung und Verbesserung. Die Bedrohungslandschaft und die Geschäftsanforderungen ändern sich ständig. Daher müssen die Sicherheitsrichtlinien und -kontrollen regelmäßig überwacht, getestet und verfeinert werden, um ihre Wirksamkeit dauerhaft zu gewährleisten.7

Schlussfolgerung

Die vorgestellte Zero-Trust-Architektur für ein KI-gestütztes RAG-System stellt einen fundamentalen Wandel in der Sicherheitsstrategie der öffentlichen Verwaltung dar. Sie ersetzt ein veraltetes, auf implizitem Vertrauen basierendes Modell durch einen robusten, resilienten und dynamischen Ansatz, der den Realitäten der modernen digitalen Welt gerecht wird. Durch die konsequente Anwendung der Prinzipien "Niemals vertrauen, immer verifizieren", "Von einer Kompromittierung ausgehen" und "Zugriff mit den geringsten Rechten" wird ein Sicherheitsniveau erreicht, das für den verantwortungsvollen Einsatz von KI-Technologien im Umgang mit sensiblen Regierungs- und Bürgerdaten unerlässlich ist.
Die Architektur adressiert nicht nur die allgemeinen Herausforderungen der Cybersicherheit, sondern auch die spezifischen Risiken, die mit KI-Systemen verbunden sind, wie Datenvergiftung, Modell-Diebstahl und Prompt-Injektion. Durch die Kombination einer hybriden IAM-Strategie, strikter Netzwerk-Mikrosegmentierung, anwendungsorchestrierten Datensicherheitskontrollen und kontinuierlicher Überwachung wird ein mehrschichtiges Verteidigungssystem ("Defense in Depth") geschaffen, das die Angriffsfläche minimiert und die laterale Ausbreitung von Bedrohungen verhindert.
Ein zentraler Pfeiler dieser Architektur ist die Anerkennung der Datenvielfalt durch eine Polyglot-Persistence-Strategie, die durch eine einheitliche Adapterschicht (UDS3) gemanagt wird. Die daraus resultierende verteilte Natur des Systems wird durch das Saga-Pattern beherrschbar gemacht. Die bewusste Entscheidung für eine orchestrierte Saga stellt sicher, dass alle mehrstufigen Prozesse über die verschiedenen Datenspeicher hinweg nicht nur technisch konsistent, sondern auch rechtlich einwandfrei und lückenlos auditierbar sind – eine unabdingbare Voraussetzung für das Verwaltungshandeln.69
Die Umsetzung dieser Strategie ist anspruchsvoll und erfordert nicht nur technologische Investitionen, sondern auch eine organisatorische Weiterentwicklung, insbesondere in den Bereichen IAM-Expertise und Data Governance. Der vorgeschlagene gestufte Implementierungsfahrplan bietet einen pragmatischen und risikominimierten Weg zur Realisierung dieser Vision.
Letztendlich ist diese Zero-Trust-Architektur mehr als nur ein Sicherheitskonzept. Sie ist ein strategischer Wegbereiter, der es der öffentlichen Verwaltung ermöglicht, die transformative Kraft der Künstlichen Intelligenz sicher und souverän zu nutzen. Sie schafft das notwendige Fundament des Vertrauens, um die digitale Transformation voranzutreiben, die Effizienz zu steigern und den Bürgern innovative, datengestützte Dienstleistungen anzubieten, ohne dabei die fundamentalen Prinzipien der Sicherheit und des Datenschutzes zu kompromittieren.
Referenzen
1.	Zero-Trust-Architektur: Definition, Hauptkomponenten und Funktionen - Ekran System, Zugriff am September 29, 2025, https://www.syteca.com/de/blog/zero-trust-sicherheitsmodells
2.	Zero-Trust-Architektur: Niemals vertrauen, immer überprüfen - Kiteworks, Zugriff am September 29, 2025, https://www.kiteworks.com/de/cybersecurity-risikomanagement/zero-trust-architektur-niemals-vertrauen-immer-ueberpruefen/
3.	What Is a Zero Trust Architecture? - Zscaler, Inc., Zugriff am September 29, 2025, https://www.zscaler.com/resources/security-terms-glossary/what-is-zero-trust-architecture
4.	Zero Trust Architecture: Strategies and Benefits | Gartner, Zugriff am September 29, 2025, https://www.gartner.com/en/cybersecurity/topics/zero-trust-architecture
5.	NIST Offers 19 Ways to Build Zero Trust Architectures, Zugriff am September 29, 2025, https://www.nist.gov/news-events/news/2025/06/nist-offers-19-ways-build-zero-trust-architectures
6.	What is Database Security | Threats & Best Practices - Imperva, Zugriff am September 29, 2025, https://www.imperva.com/learn/data-security/database-security/
7.	What Is Zero Trust Architecture? Key Elements and Use Cases - Palo Alto Networks, Zugriff am September 29, 2025, https://www.paloaltonetworks.com/cyberpedia/what-is-a-zero-trust-architecture
8.	What is RAG? - Retrieval-Augmented Generation AI Explained - AWS - Updated 2025, Zugriff am September 29, 2025, https://aws.amazon.com/what-is/retrieval-augmented-generation/
9.	What is Retrieval-Augmented Generation (RAG)? - Google Cloud, Zugriff am September 29, 2025, https://cloud.google.com/use-cases/retrieval-augmented-generation
10.	Retrieval-augmented generation - Wikipedia, Zugriff am September 29, 2025, https://en.wikipedia.org/wiki/Retrieval-augmented_generation
11.	Detecting Exposed LLM Servers: Shodan Case Study on Ollama, Zugriff am September 29, 2025, https://blogs.cisco.com/security/detecting-exposed-llm-servers-shodan-case-study-on-ollama
12.	How to Run a Local LLM: Complete Guide to Setup & Best Models (2025) - n8n Blog, Zugriff am September 29, 2025, https://blog.n8n.io/local-llm/
13.	Polyglot Persistence: A Strategic Approach to Modern Data Architecture - Medium, Zugriff am September 29, 2025, https://medium.com/@rachoork/polyglot-persistence-a-strategic-approach-to-modern-data-architecture-e2a4f957f50b
14.	Polyglot persistence vs multi-model databases for microservices - CircleCI, Zugriff am September 29, 2025, https://circleci.com/blog/polyglot-vs-multi-model-databases/
15.	SQLite vs. Chroma: A Comparative Analysis for Managing Vector Embeddings, Zugriff am September 29, 2025, https://dev.to/stephenc222/sqlite-vs-chroma-a-comparative-analysis-for-managing-vector-embeddings-4i76
16.	ChromaDB and SQLite - YouTube, Zugriff am September 29, 2025, https://www.youtube.com/shorts/ECpiByWaNBQ
17.	Leveraging Neo4j for Effective Identity Access Management - DZone, Zugriff am September 29, 2025, https://dzone.com/articles/leveraging-neo4j-for-identity-access-management
18.	Understanding and Securing Exposed Ollama Instances | UpGuard, Zugriff am September 29, 2025, https://www.upguard.com/blog/understanding-and-securing-exposed-ollama-instances
19.	Database Security: An Essential Guide - IBM, Zugriff am September 29, 2025, https://www.ibm.com/think/topics/database-security
20.	Securing Your AI: Critical Vulnerabilities Found in Popular Ollama Framework, Zugriff am September 29, 2025, https://ridgesecurity.ai/blog/securing-your-ai-critical-vulnerabilities-found-in-popular-ollama-framework/
21.	Active Directory vs. Microsoft Entra ID: A Sysadmin's Guide - ERP Software Blog, Zugriff am September 29, 2025, https://erpsoftwareblog.com/2025/07/active-directory-vs-microsoft-entra-id-a-sysadmins-guide/
22.	Entra ID vs Active Directory - Comparing Identity Platforms, Zugriff am September 29, 2025, https://petri.com/entra-id-vs-active-directory/
23.	Active Directory versus Microsoft Entra ID: What's the difference? - PDQ, Zugriff am September 29, 2025, https://www.pdq.com/blog/active-directory-versus-microsoft-entra-id/
24.	Keycloak and its Competitors: A Comparative Analysis of Enterprise IAM Solutions, Zugriff am September 29, 2025, https://www.siriusopensource.com/en-us/blog/keycloak-and-its-competitors-comparative-analysis-enterprise-iam-solutions
25.	Keycloak, Zugriff am September 29, 2025, https://www.keycloak.org/
26.	Common problems with Keycloak: Not knowing its strengths - intension GmbH, Zugriff am September 29, 2025, https://www.intension.de/en/infoblog/keycloak-strengths/
27.	Keycloak: What, when and why to choose? - Sennovate, Zugriff am September 29, 2025, https://sennovate.com/the-mssp-guide-to-keycloak/
28.	Keycloak vs Microsoft Azure AD vs ZITADEL Comparison | SaaSworthy.com, Zugriff am September 29, 2025, https://www.saasworthy.com/compare/keycloak-vs-microsoft-azure-ad-vs-zitadel?pIds=5998,10482,32120
29.	Keycloak Review 2025: Features, Pricing & Alternatives - Infisign, Zugriff am September 29, 2025, https://www.infisign.ai/reviews/keycloak
30.	Is Keycloak worth the maintenance? : r/devops - Reddit, Zugriff am September 29, 2025, https://www.reddit.com/r/devops/comments/1ak7pex/is_keycloak_worth_the_maintenance/
31.	Manage Group Managed Service Accounts | Microsoft Learn, Zugriff am September 29, 2025, https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/manage/group-managed-service-accounts/group-managed-service-accounts/manage-group-managed-service-accounts
32.	gMSA Guide: Group Managed Service Account Security & Deployment - Varonis, Zugriff am September 29, 2025, https://www.varonis.com/blog/gmsa
33.	Group Managed Service Accounts - NC State Active Directory, Zugriff am September 29, 2025, https://activedirectory.ncsu.edu/group-managed-service-accounts-gmsas/
34.	Using Group Managed Service Accounts - User Guide for Microsoft Hyper-V, Zugriff am September 29, 2025, https://helpcenter.veeam.com/docs/backup/hyperv/using_gmsa.html
35.	How does Kerberos work? - MIT, Zugriff am September 29, 2025, https://web.mit.edu/kerberos/kfw-4.1/kfw-4.1/kfw-4.1-help/html/how_kerberos_works.htm
36.	Protocol Tutorial - MIT Kerberos Consortium, Zugriff am September 29, 2025, https://www.kerberos.org/software/tutorial.html
37.	Kerberos: The Network Authentication Protocol - MIT, Zugriff am September 29, 2025, https://web.mit.edu/kerberos/
38.	Kerberos (protocol) - Wikipedia, Zugriff am September 29, 2025, https://en.wikipedia.org/wiki/Kerberos_(protocol)
39.	What Is Kerberos? Kerberos Authentication Explained | Fortinet, Zugriff am September 29, 2025, https://www.fortinet.com/resources/cyberglossary/kerberos-authentication
40.	Kerberos authentication overview in Windows Server | Microsoft Learn, Zugriff am September 29, 2025, https://learn.microsoft.com/en-us/windows-server/security/kerberos/kerberos-authentication-overview
41.	www.appviewx.com, Zugriff am September 29, 2025, https://www.appviewx.com/blogs/why-mutual-tls-mtls-is-critical-for-securing-microservices-communications-in-a-service-mesh/#:~:text=How%20mTLS%20Helps%20Secure%20Service,to%20establish%20a%20secure%20connection.
42.	What is mTLS? | Mutual TLS - Cloudflare, Zugriff am September 29, 2025, https://www.cloudflare.com/learning/access-management/what-is-mutual-tls/
43.	Understanding Mutual TLS (MTLS) Authentication: How It Works, Zugriff am September 29, 2025, https://www.securew2.com/blog/mutual-tls-mtls-authentication
44.	What Is Mutual TLS (mTLS) Authentication? - Infisign, Zugriff am September 29, 2025, https://www.infisign.ai/blog/mutual-tls-mtls-authentication
45.	mTLS Explained - Beeceptor, Zugriff am September 29, 2025, https://beeceptor.com/docs/concepts/mtls/
46.	Securely Expose Remote Ollama Endpoints to your Development Machine, Zugriff am September 29, 2025, https://akyriako.medium.com/securely-expose-remote-ollama-endpoints-to-your-development-machine-8be007d73d33
47.	PSA: Secure Your Ollama / LLM Ports ( Even on Home LAN ) - Reddit, Zugriff am September 29, 2025, https://www.reddit.com/r/ollama/comments/1mn653l/psa_secure_your_ollama_llm_ports_even_on_home_lan/
48.	“Secure Mode” for Ollama (auth, safe defaults, restricted blob/model ops) #11941 - GitHub, Zugriff am September 29, 2025, https://github.com/ollama/ollama/issues/11941
49.	Ollama: The Complete Guide to Running Large Language Models Locally in 2025, Zugriff am September 29, 2025, https://collabnix.com/ollama-the-complete-guide-to-running-large-language-models-locally-in-2025/
50.	What is Polyglot Persistence and Why is it Awful? - HarperDB, Zugriff am September 29, 2025, https://www.harpersystems.dev/post/what-is-polyglot-persistence-and-why-is-it-awful
51.	Row-level security (RLS) with Power BI - Microsoft Fabric, Zugriff am September 29, 2025, https://learn.microsoft.com/en-us/fabric/security/service-admin-row-level-security
52.	Implementing Row-Level Security in Snowflake - Galaxy, Zugriff am September 29, 2025, https://www.getgalaxy.io/learn/glossary/implementing-row-level-security-in-snowflake
53.	Row-Level Security - SQL Server | Microsoft Learn, Zugriff am September 29, 2025, https://learn.microsoft.com/en-us/sql/relational-databases/security/row-level-security?view=sql-server-ver17
54.	Dynamic Row-Level Security (RLS) Implementation in Power BI (Part 1) - Medium, Zugriff am September 29, 2025, https://medium.com/microsoftazure/dynamic-row-level-security-rls-implementation-in-power-bi-part-1-b73b513e952e
55.	Dynamic Row Level Security in Power BI - YouTube, Zugriff am September 29, 2025, https://www.youtube.com/watch?v=jphj40tBPD8
56.	LDAP integration - Operations Manual - Neo4j, Zugriff am September 29, 2025, https://neo4j.com/docs/operations-manual/current/authentication-authorization/ldap-integration/
57.	Role-based access control - Operations Manual - Neo4j, Zugriff am September 29, 2025, https://neo4j.com/docs/operations-manual/current/authentication-authorization/manage-privileges/
58.	What is Application Security | Types, Tools & Best Practices - Imperva, Zugriff am September 29, 2025, https://www.imperva.com/learn/application-security/application-security/
59.	Cutting API Latency: The Impact of Simplifying JWT Encryption | by ..., Zugriff am September 29, 2025, https://medium.com/@thiagosalvatore/cutting-api-latency-the-impact-of-simplifying-jwt-encryption-6c8da058aa10
60.	Does jwt with asymmetric algorithm have a bad performance?, Zugriff am September 29, 2025, https://security.stackexchange.com/questions/268596/does-jwt-with-asymmetric-algorithm-have-a-bad-performance
61.	Node JS: JWT verify vs redis query performance comparison? - Stack Overflow, Zugriff am September 29, 2025, https://stackoverflow.com/questions/66588143/node-js-jwt-verify-vs-redis-query-performance-comparison
62.	mTLS: When certificate authentication is done wrong - The GitHub Blog, Zugriff am September 29, 2025, https://github.blog/security/vulnerability-research/mtls-when-certificate-authentication-is-done-wrong/
63.	Strategy - Refactoring.Guru, Zugriff am September 29, 2025, https://refactoring.guru/design-patterns/strategy
64.	Strategy Design Pattern - GeeksforGeeks, Zugriff am September 29, 2025, https://www.geeksforgeeks.org/system-design/strategy-pattern-set-1/
65.	Spring Test & Security: How to mock authentication? - Stack Overflow, Zugriff am September 29, 2025, https://stackoverflow.com/questions/15203485/spring-test-security-how-to-mock-authentication
66.	Best practices about mocking third party sources in local development : r/webdev - Reddit, Zugriff am September 29, 2025, https://www.reddit.com/r/webdev/comments/1lb6icb/best_practices_about_mocking_third_party_sources/
67.	Strategy Design Pattern in Spring - DEV Community, Zugriff am September 29, 2025, https://dev.to/dayanandaeswar/strategy-design-pattern-in-spring-2l12
68.	Implementing strategy pattern via configuration - Software Engineering Stack Exchange, Zugriff am September 29, 2025, https://softwareengineering.stackexchange.com/questions/366716/implementing-strategy-pattern-via-configuration
69.	Polyglot Persistence und Saga-Muster
